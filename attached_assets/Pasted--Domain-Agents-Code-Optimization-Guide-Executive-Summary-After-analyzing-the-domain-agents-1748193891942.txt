# Domain Agents Code Optimization Guide

## Executive Summary

After analyzing the domain agents code, I've identified several optimization opportunities across performance, design patterns, maintainability, and functionality. The code is well-structured but can benefit from improvements in async handling, caching, configuration management, and extensibility.

## Key Optimization Areas

### 1. Performance Optimizations

#### Concurrent Processing
**Current Issue**: Sequential processing of evidence in domain agents
**Solution**: Use `asyncio.gather()` for parallel processing

```python
# Instead of sequential processing:
for ev in evidence:
    # process one by one

# Use concurrent processing:
async def process_evidence(self, evidence: List[Evidence]) -> List[DomainInsight]:
    tasks = [
        self._analyze_market_evidence(market_evidence),
        self._analyze_risk_evidence(risk_evidence),
        self._analyze_trend_evidence(trend_evidence)
    ]
    results = await asyncio.gather(*tasks)
    return [r for r in results if r is not None]
```

#### Caching Mechanism
**Current Issue**: No caching of analysis results
**Solution**: Implement LRU cache for repeated queries

```python
from functools import lru_cache
import hashlib

class CachedAnalysisManager:
    def __init__(self, cache_size: int = 128):
        self._cache = {}
        self.cache_size = cache_size
    
    def get_cache_key(self, query: str, evidence_ids: List[str]) -> str:
        content = f"{query}::{':'.join(sorted(evidence_ids))}"
        return hashlib.md5(content.encode()).hexdigest()
    
    async def get_or_compute(self, key: str, compute_func):
        if key in self._cache:
            return self._cache[key]
        
        result = await compute_func()
        
        # Simple LRU: remove oldest if cache full
        if len(self._cache) >= self.cache_size:
            oldest = next(iter(self._cache))
            del self._cache[oldest]
        
        self._cache[key] = result
        return result
```

### 2. Design Pattern Improvements

#### Strategy Pattern for Analysis
**Current Issue**: Hard-coded analysis logic in each agent
**Solution**: Implement pluggable analysis strategies

```python
from typing import Protocol

class AnalysisStrategy(Protocol):
    async def analyze(self, evidence: List[Evidence]) -> Optional[DomainInsight]:
        ...

class TrendAnalysisStrategy:
    def __init__(self, domain: str):
        self.domain = domain
    
    async def analyze(self, evidence: List[Evidence]) -> Optional[DomainInsight]:
        # Reusable trend analysis logic
        pass

class FinancialAnalystAgent(BaseDomainAgent):
    def __init__(self):
        super().__init__("Financial Analysis")
        self.analysis_strategies = {
            "trend": TrendAnalysisStrategy("Financial Markets"),
            "risk": RiskAnalysisStrategy("Financial Markets"),
            "market": MarketAnalysisStrategy("Financial Markets")
        }
```

#### Configuration-Driven Keywords
**Current Issue**: Hard-coded keywords in constructors
**Solution**: External configuration file

```python
# config/domain_configs.yaml
financial:
  keywords:
    - market
    - trading
    - investment
  analysis_patterns:
    trend_analysis: [uptrend, downtrend, sideways]
  thresholds:
    relevance_score: 0.3
    
# domain_config.py
import yaml
from typing import Dict, Any

class DomainConfig:
    def __init__(self, config_path: str = "config/domain_configs.yaml"):
        with open(config_path, 'r') as f:
            self.configs = yaml.safe_load(f)
    
    def get_domain_config(self, domain: str) -> Dict[str, Any]:
        return self.configs.get(domain, {})
```

### 3. Error Handling & Resilience

#### Robust Error Handling
**Current Issue**: Limited error handling for evidence processing
**Solution**: Implement comprehensive error handling

```python
class DomainAgentError(Exception):
    """Base exception for domain agent errors"""
    pass

class EvidenceProcessingError(DomainAgentError):
    """Raised when evidence processing fails"""
    pass

async def process_evidence_safely(self, evidence: List[Evidence]) -> List[DomainInsight]:
    insights = []
    errors = []
    
    for ev in evidence:
        try:
            insight = await self._process_single_evidence(ev)
            if insight:
                insights.append(insight)
        except Exception as e:
            errors.append({
                "evidence_id": ev.id,
                "error": str(e),
                "timestamp": time.time()
            })
            logger.error(f"Failed to process evidence {ev.id}: {e}")
    
    if errors:
        # Store errors for analysis
        self._error_history.extend(errors)
    
    return insights
```

### 4. Enhanced Scoring & Metrics

#### Weighted Scoring System
**Current Issue**: Simple keyword counting for relevance
**Solution**: Implement weighted scoring with context awareness

```python
class RelevanceScorer:
    def __init__(self):
        self.keyword_weights = {
            "primary": 1.0,    # Core domain keywords
            "secondary": 0.5,  # Related keywords
            "contextual": 0.3  # Context-dependent keywords
        }
    
    def calculate_relevance(
        self, 
        query: str, 
        keywords: Dict[str, List[str]]
    ) -> float:
        query_lower = query.lower()
        query_tokens = set(query_lower.split())
        
        score = 0.0
        matches = []
        
        for category, weight in self.keyword_weights.items():
            category_keywords = keywords.get(category, [])
            for keyword in category_keywords:
                if keyword in query_lower:
                    # Bonus for exact token match
                    if keyword in query_tokens:
                        score += weight * 1.2
                    else:
                        score += weight
                    matches.append((keyword, category))
        
        # Normalize based on query length
        normalized_score = min(1.0, score / (len(query_tokens) ** 0.5))
        return normalized_score
```

### 5. Domain Agent Registry

#### Dynamic Agent Registration
**Current Issue**: Hard-coded agent dictionary
**Solution**: Plugin-based architecture

```python
from typing import Type
import importlib
import pkgutil

class DomainAgentRegistry:
    def __init__(self):
        self._agents: Dict[str, Type[BaseDomainAgent]] = {}
        self._instances: Dict[str, BaseDomainAgent] = {}
    
    def register(self, name: str, agent_class: Type[BaseDomainAgent]):
        """Register a domain agent class"""
        self._agents[name] = agent_class
        logger.info(f"Registered domain agent: {name}")
    
    def get_agent(self, name: str) -> Optional[BaseDomainAgent]:
        """Get or create agent instance"""
        if name not in self._instances and name in self._agents:
            self._instances[name] = self._agents[name]()
        return self._instances.get(name)
    
    def discover_agents(self, package_name: str = "domain_agents"):
        """Auto-discover and register agents from a package"""
        package = importlib.import_module(package_name)
        
        for _, module_name, _ in pkgutil.iter_modules(package.__path__):
            module = importlib.import_module(f"{package_name}.{module_name}")
            
            for attr_name in dir(module):
                attr = getattr(module, attr_name)
                if (isinstance(attr, type) and 
                    issubclass(attr, BaseDomainAgent) and 
                    attr != BaseDomainAgent):
                    
                    agent_name = attr_name.replace("Agent", "").lower()
                    self.register(agent_name, attr)
```

### 6. Enhanced Insight Generation

#### Confidence Calculation
**Current Issue**: Simple averaging for confidence scores
**Solution**: Weighted confidence with source quality

```python
class ConfidenceCalculator:
    def __init__(self):
        self.source_weights = {
            "peer_reviewed": 1.0,
            "official": 0.9,
            "news": 0.7,
            "blog": 0.5,
            "social_media": 0.3
        }
    
    def calculate_confidence(
        self, 
        evidence: List[Evidence],
        agreement_factor: float = 1.0
    ) -> float:
        if not evidence:
            return 0.0
        
        weighted_sum = 0.0
        total_weight = 0.0
        
        for ev in evidence:
            source_type = self._determine_source_type(ev.source)
            weight = self.source_weights.get(source_type, 0.5)
            
            weighted_sum += ev.credibility_score * weight
            total_weight += weight
        
        base_confidence = weighted_sum / total_weight if total_weight > 0 else 0.0
        
        # Apply agreement factor (how well evidence agrees)
        return min(1.0, base_confidence * agreement_factor)
```

### 7. Async Context Management

#### Resource Management
**Current Issue**: No cleanup of resources
**Solution**: Implement async context managers

```python
class DomainAgentOrchestrator:
    async def __aenter__(self):
        """Initialize resources"""
        self.session = aiohttp.ClientSession()
        await self._initialize_agents()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Cleanup resources"""
        await self.session.close()
        for agent in self._instances.values():
            if hasattr(agent, 'cleanup'):
                await agent.cleanup()
    
    async def _initialize_agents(self):
        """Initialize all agents concurrently"""
        init_tasks = []
        for name, agent in self.agents.items():
            if hasattr(agent, 'initialize'):
                init_tasks.append(agent.initialize())
        
        if init_tasks:
            await asyncio.gather(*init_tasks)
```

### 8. Testing & Monitoring

#### Performance Monitoring
```python
import time
from contextlib import asynccontextmanager

class PerformanceMonitor:
    def __init__(self):
        self.metrics = defaultdict(list)
    
    @asynccontextmanager
    async def measure(self, operation: str):
        start = time.perf_counter()
        try:
            yield
        finally:
            duration = time.perf_counter() - start
            self.metrics[operation].append(duration)
            
            if duration > 1.0:  # Log slow operations
                logger.warning(f"Slow operation {operation}: {duration:.2f}s")
    
    def get_stats(self, operation: str) -> Dict[str, float]:
        times = self.metrics.get(operation, [])
        if not times:
            return {}
        
        return {
            "count": len(times),
            "mean": sum(times) / len(times),
            "min": min(times),
            "max": max(times)
        }
```

### 9. Implementation Priority

1. **High Priority**
   - Concurrent processing (immediate performance boost)
   - Error handling (system stability)
   - Caching mechanism (reduce redundant computation)

2. **Medium Priority**
   - Configuration management (maintainability)
   - Weighted scoring system (accuracy improvement)
   - Performance monitoring (observability)

3. **Low Priority**
   - Plugin architecture (future extensibility)
   - Advanced confidence calculation (refinement)

### 10. Example Optimized Agent

```python
class OptimizedFinancialAnalystAgent(BaseDomainAgent):
    def __init__(self, config: DomainConfig, cache_manager: CachedAnalysisManager):
        super().__init__("Financial Analysis")
        self.config = config.get_domain_config("financial")
        self.cache = cache_manager
        self.scorer = RelevanceScorer()
        self.monitor = PerformanceMonitor()
        
        # Load configuration
        self.specialized_keywords = self.config.get("keywords", [])
        self.analysis_strategies = self._load_strategies()
    
    async def analyze_query(self, query: str) -> Dict[str, Any]:
        async with self.monitor.measure("query_analysis"):
            # Use cache if available
            cache_key = self.cache.get_cache_key(query, [])
            
            return await self.cache.get_or_compute(
                cache_key,
                lambda: self._perform_analysis(query)
            )
    
    async def process_evidence(self, evidence: List[Evidence]) -> List[DomainInsight]:
        async with self.monitor.measure("evidence_processing"):
            # Process evidence concurrently
            grouped_evidence = self._group_evidence(evidence)
            
            tasks = [
                strategy.analyze(evidence_group)
                for strategy_name, evidence_group in grouped_evidence.items()
                if strategy_name in self.analysis_strategies
            ]
            
            insights = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Filter out exceptions and None results
            return [
                insight for insight in insights 
                if isinstance(insight, DomainInsight) and insight is not None
            ]
```

## Conclusion

These optimizations will significantly improve the domain agents system by:
- Reducing processing time through concurrent execution
- Improving reliability with better error handling
- Enhancing maintainability through configuration management
- Increasing accuracy with weighted scoring
- Providing better observability through monitoring

The modular approach allows for gradual implementation based on priority and resources available.