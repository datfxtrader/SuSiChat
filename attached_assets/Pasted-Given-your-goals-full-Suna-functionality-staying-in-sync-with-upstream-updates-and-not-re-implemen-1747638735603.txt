Given your goals—full Suna functionality, staying in sync with upstream updates, and not re-implementing all of Suna’s Python stack in Node—I’d recommend setting up the full Suna backend as its own microservice alongside your Tongkeeper service, all within your Replit project. Here’s why and how:

Why go full-Suna now
Upstream Compatibility & Updates
You’ll be able to git pull new Suna releases (bug fixes, new tools, performance tweaks) and immediately rebuild the container—no merging or re-writing in JS.

Complete Feature Set
Suna’s sandboxed tools (browser automation, code execution, calculators, etc.) and agent orchestration are battle-tested. A mock implementation can’t match that breadth.

Separation of Concerns

Suna remains the “brain” (Python/FastAPI, Docker containers, its own database/schema).

Tongkeeper remains the “face” and orchestration layer (Node/Express, React, auth, scheduling, family-chat, memory).

Independent Scaling & Maintenance
If your LLM inference or sandbox tools need more CPU/RAM, you simply scale up Suna’s container. If you need more web-server capacity or database connections, you scale Tongkeeper separately.

Recommended Setup on Replit
Add a Python Container for Suna

In your Replit repo, create a suna/ directory and clone the Kortix AI Suna code.

Add a Dockerfile in suna/ (or use their provided one) installing all Python deps.

Configure Environment Variables

DEEPSEEK_API_KEY (to wire Suna’s LLM integration to your DeepSeek key)

Any other keys for tools you want (you can leave Tavily or OpenAI empty until needed).

DATABASE_URL pointing to a separate schema or table set in your existing Postgres (or a brand-new DB).

Wire It Up with Docker Compose

yaml
Copy
Edit
version: "3.8"
services:
  suna:
    build: ./suna
    env_file: suna/.env
    ports:
      - "8000:8000"
    depends_on:
      - db
  tongkeeper:
    build: ./tongkeeper
    env_file: tongkeeper/.env
    ports:
      - "3000:3000"
    depends_on:
      - suna
      - db
  db:
    image: postgres:15
    env_file: .env
    volumes:
      - pgdata:/var/lib/postgresql/data
volumes:
  pgdata:
Suna listens on port 8000, Tongkeeper on 3000, both share the same Postgres if you like (just use distinct schemas), or you can spin up a second DB container.

In Tongkeeper, Call Suna’s API

js
Copy
Edit
// pseudocode in Node/Express
const response = await fetch("http://suna:8000/agent/chat", {
  method: "POST",
  headers: { "Content-Type": "application/json" },
  body: JSON.stringify({ prompt, tools: [...] }),
});
const { reply } = await response.json();
CI/CD & Upstream Pulls

In your Replit CI (or GitHub Actions), include steps to cd suna && git pull origin main && docker build ./suna before deploying.

You can pin to Suna releases or float on main for the latest.

Alternative: Separate Hosts
If you’d rather run Suna in an entirely different Replit project (or VM) you can—just point your Tongkeeper service to its public URL. But hosting side-by-side simplifies networking and credentials.

Bottom line:

Yes, set up the full Suna backend now as a dedicated microservice (in the same Replit environment under Docker Compose). Use your DeepSeek API key to configure its LLM, stub out any tools you don’t need yet, and keep your Node.js Tongkeeper service calling into it. This gives you the richest feature set and smoothest path for future Suna community updates—without ever rewriting Python into JavaScript.