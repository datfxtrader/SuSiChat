// Fix for database connection timeouts during long research operations
// Add to your database configuration file (likely server/database.ts or similar)

import { Pool } from 'pg';

// Enhanced PostgreSQL pool configuration for long-running operations
const pool = new Pool({
  connectionString: process.env.DATABASE_URL,
  
  // CONNECTION TIMEOUT FIXES
  connectionTimeoutMillis: 30000,     // 30 seconds to establish connection
  idleTimeoutMillis: 600000,         // 10 minutes idle timeout (was probably 30s)
  max: 20,                           // Maximum connections in pool
  min: 5,                            // Minimum connections to maintain
  
  // KEEP-ALIVE SETTINGS - Prevents administrator disconnect
  keepAlive: true,
  keepAliveInitialDelayMillis: 10000, // 10 seconds before first keep-alive
  
  // QUERY TIMEOUT - Allow long research operations
  query_timeout: 600000,             // 10 minutes for long queries
  statement_timeout: 600000,         // 10 minutes statement timeout
});

// Enhanced query wrapper with retry logic
export async function executeResearchQuery(query: string, params: any[] = []) {
  const client = await pool.connect();
  
  try {
    // Set session timeout for this specific research operation
    await client.query('SET statement_timeout = 600000'); // 10 minutes
    await client.query('SET idle_in_transaction_session_timeout = 600000');
    
    console.log('ğŸ”— Database client connected for research operation');
    
    const result = await client.query(query, params);
    
    console.log('âœ… Research query completed successfully');
    return result;
    
  } catch (error) {
    console.error('âŒ Database query failed:', error);
    
    // Retry logic for connection issues
    if (error.code === 'ECONNRESET' || error.message.includes('administrator command')) {
      console.log('ğŸ”„ Retrying database operation after connection reset...');
      
      // Wait 2 seconds and retry once
      await new Promise(resolve => setTimeout(resolve, 2000));
      
      try {
        const retryResult = await client.query(query, params);
        console.log('âœ… Retry successful');
        return retryResult;
      } catch (retryError) {
        console.error('âŒ Retry also failed:', retryError);
        throw retryError;
      }
    }
    
    throw error;
  } finally {
    client.release();
    console.log('ğŸ”“ Database client released');
  }
}

// Alternative: Store results in memory as backup
const researchResultsCache = new Map();

export async function storeResearchResults(conversationId: string, results: any) {
  try {
    // Try database first
    await executeResearchQuery(
      'INSERT INTO research_results (conversation_id, results, created_at) VALUES ($1, $2, NOW())',
      [conversationId, JSON.stringify(results)]
    );
    
    console.log('âœ… Results stored in database');
    
  } catch (error) {
    console.error('âŒ Database storage failed, using memory cache:', error);
    
    // Fallback to memory storage
    researchResultsCache.set(conversationId, {
      results,
      timestamp: new Date().toISOString()
    });
    
    console.log('ğŸ’¾ Results cached in memory as fallback');
  }
}

export async function getResearchResults(conversationId: string) {
  try {
    // Try database first
    const result = await executeResearchQuery(
      'SELECT results FROM research_results WHERE conversation_id = $1 ORDER BY created_at DESC LIMIT 1',
      [conversationId]
    );
    
    if (result.rows.length > 0) {
      return JSON.parse(result.rows[0].results);
    }
    
  } catch (error) {
    console.error('âŒ Database retrieval failed, checking memory cache:', error);
  }
  
  // Fallback to memory cache
  const cached = researchResultsCache.get(conversationId);
  if (cached) {
    console.log('ğŸ’¾ Retrieved results from memory cache');
    return cached.results;
  }
  
  return null;
}